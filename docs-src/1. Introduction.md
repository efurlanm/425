Many simulations are mathematically modeled by Partial Differential Equations (PDEs), which have derivatives in space and time. However, the coefficients of these derivatives are unknowns, and the PDEs are usually solved by a numerical method, like the finite difference method. Recent works proposed to solve PDEs using Deep Neural Networks (DNN), which are machine learning algorithms. The universal approximation theorem states that a neural network can approximate any continuous function, as long as the network has a sufficient number of hidden layers and employs nonlinear activation functions.
This approach requires knowledge of a large set of sample points in space and time domain (called Collocation Points - CPs) to train the DNN, which can be obtained either by observation, or if the model is known, it can be generated by numerical methods.
As the required number of CPs would be very high, Physics-Informed Neural Networks (PINNs) were proposed and allow the use of a smaller number of CPs as they include the underlying physical laws related to the simulation in the DNN.

PINNs can be used in direct problems (inference or solution), where the PDE and parameters are known and we want to obtain the simulation result, and in inverse problems (identification or discovery) where we have the dataset and want to obtain the PDE parameters.
A work by Chevallier et al. [\[1\]](References.md#Chevallier2000) describes a speedup of 7 using DNN to obtain parameters in the Longwave Radiative Transfer model from ECMWF (European Center for Medium-Range Weather Forecasts), showing the importance of using DNN to obtain parametric representation in numerical modeling of various atmospheric processes.
Krasnopolsky et al. [\[2\]](References.md#Krasnopolsky2006) also cites speedups between $10$ to $10^5$ using DNN in the parametrization of physical models in oceanic and atmospheric numerical models.
Furthermore, there is also the possibility of using PINN in cases where the model (or the PDE that describes it) is known, to reduce the size of the dataset necessary to train the DNN, thus increasing efficiency, or in cases where there is noise in the sample and we want the underlying physical law to help deal with it.

This work evaluates data-driven parameter discovery of the one-dimensional Burgers' equation, a PDE with derivatives in space and time, obtained through PINN, for different hyperparameters and dataset sizes.
The work seeks to answer the question “what is the ideal combination of hyperparameters and dataset size, for this specific problem?”, in order to seek the best model for the expected result.

The PINN discovery is evaluated in terms of accuracy and DNN training processing time, executed on the Santos Dumont supercomputer (SDumont) at the National Scientific Computing Laboratory (LNCC). The tests were carried out on a Bull Sequana X1120 processing node with two 2.1 GHz 24-core Intel Xeon Gold 6252 Skylake processors (totaling 48 cores), 384 GB of main RAM, and four Nvidia Volta V100 GPUs. Only one GPU is used in this work. All data and codes used in this manuscript are publicly available on GitHub at <https://github.com/efurlanm/425/>.

The discovery of EDPs by PINNs is relatively recent and the acquisition of knowledge in this approach can be useful for application in some specific modules of numerical models used at CPTEC/INPE for weather and climate prediction.
