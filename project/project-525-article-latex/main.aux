\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{Chevallier2000}
\citation{Krasnopolsky2006}
\citation{Raissi2019}
\@writefile{toc}{\contentsline {section}{\numberline {I}Introduction}{1}{section.1}\protected@file@percent }
\citation{Cuomo2022}
\citation{Cuomo2022}
\citation{Cuomo2022}
\citation{Burkardt2013}
\citation{Xu2022}
\citation{Koehrsen2018}
\citation{Xu2022}
\@writefile{toc}{\contentsline {section}{\numberline {II}Material and methods}{2}{section.2}\protected@file@percent }
\newlabel{sec:meth}{{II}{2}{Material and methods}{section.2}{}}
\newlabel{eq:burg}{{1}{2}{Material and methods}{equation.2.1}{}}
\newlabel{eq:ftx}{{2}{2}{Material and methods}{equation.2.2}{}}
\newlabel{eq:mse}{{3}{2}{Material and methods}{equation.2.3}{}}
\newlabel{eq:error}{{4}{2}{Material and methods}{equation.2.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {II-A}}PINN Implementation}{2}{subsection.2.1}\protected@file@percent }
\citation{Raissi2019}
\newlabel{lst:utx}{{1}{3}{Code snippet that implements $u(t,x)$}{lstlisting.1}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {1}Code snippet that implements $u(t,x)$}{3}{lstlisting.1}\protected@file@percent }
\newlabel{lst:ftx}{{2}{3}{Code snippet that implements $f(t,x)$}{lstlisting.2}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {2}Code snippet that implements $f(t,x)$}{3}{lstlisting.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {III}Results}{3}{section.3}\protected@file@percent }
\newlabel{sec:resu}{{III}{3}{Results}{section.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {III-A}}Visual assessment}{3}{subsection.3.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Predicted solution u(t, x) along with the training data. The horizontal axis denotes time $t$, and the vertical axis, the coordinate $x$. The marks in the graph represent the randomly assigned CPs used for training. The color scale refers to the speed u(t, x). The solid white vertical line refers to the snapshot $t=0.5$ shown in \autoref  {fig:bur2}.}}{3}{figure.1}\protected@file@percent }
\newlabel{fig:bur1}{{1}{3}{Predicted solution u(t, x) along with the training data. The horizontal axis denotes time $t$, and the vertical axis, the coordinate $x$. The marks in the graph represent the randomly assigned CPs used for training. The color scale refers to the speed u(t, x). The solid white vertical line refers to the snapshot $t=0.5$ shown in \autoref {fig:bur2}}{figure.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Superimposed solutions for PINN (in red) and numerical solution (in blue) for the $t=0.5$ snapshot.}}{3}{figure.2}\protected@file@percent }
\newlabel{fig:bur2}{{2}{3}{Superimposed solutions for PINN (in red) and numerical solution (in blue) for the $t=0.5$ snapshot}{figure.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {III-B}}Neurons x Layers}{3}{subsection.3.2}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {I}{\ignorespaces Relative L2 errors and DNN training times for different number of neurons and hidden layers. On the color scale, the best values are highlighted in red.}}{4}{table.1}\protected@file@percent }
\newlabel{tab:resu1}{{I}{4}{Relative L2 errors and DNN training times for different number of neurons and hidden layers. On the color scale, the best values are highlighted in red}{table.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Relative L2 error (\%) in function of number of neurons and hidden layers.}}{4}{figure.3}\protected@file@percent }
\newlabel{fig:rlaygrapherror2}{{3}{4}{Relative L2 error (\%) in function of number of neurons and hidden layers}{figure.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Processing times (seconds) in function of number of neurons and hidden layers.}}{4}{figure.4}\protected@file@percent }
\newlabel{fig:rlaygraptime2}{{4}{4}{Processing times (seconds) in function of number of neurons and hidden layers}{figure.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {III-C}}Neurons x Dataset}{4}{subsection.3.3}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {II}{\ignorespaces Relative L2 errors and DNN training times for different number of neurons and dataset size. The number of hidden layers is set to 8. On the color scale, the best values are highlighted in red.}}{4}{table.2}\protected@file@percent }
\newlabel{tab:rnu8error2}{{II}{4}{Relative L2 errors and DNN training times for different number of neurons and dataset size. The number of hidden layers is set to 8. On the color scale, the best values are highlighted in red}{table.2}{}}
\bibstyle{IEEEtran}
\bibdata{library}
\bibcite{Chevallier2000}{1}
\bibcite{Krasnopolsky2006}{2}
\bibcite{Raissi2019}{3}
\bibcite{Cuomo2022}{4}
\bibcite{Burkardt2013}{5}
\bibcite{Koehrsen2018}{6}
\bibcite{Xu2022}{7}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Relative L2 error (\%) in function of number of neurons and dataset size. The number of hidden layers is set to 8.}}{5}{figure.5}\protected@file@percent }
\newlabel{fig:rnu8grapherror2}{{5}{5}{Relative L2 error (\%) in function of number of neurons and dataset size. The number of hidden layers is set to 8}{figure.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Processing times (seconds) in function of number of neurons and dataset size. The number of hidden layers is set to 8.}}{5}{figure.6}\protected@file@percent }
\newlabel{fig:rnu8graphtime2}{{6}{5}{Processing times (seconds) in function of number of neurons and dataset size. The number of hidden layers is set to 8}{figure.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {III-D}}Prediction time}{5}{subsection.3.4}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {III}{\ignorespaces Prediction times for different number of neurons and hidden layers. On the color scale, the best values are highlighted in red.}}{5}{table.3}\protected@file@percent }
\newlabel{tab:rpre}{{III}{5}{Prediction times for different number of neurons and hidden layers. On the color scale, the best values are highlighted in red}{table.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {IV}Conclusions}{5}{section.4}\protected@file@percent }
\newlabel{sec:conc}{{IV}{5}{Conclusions}{section.4}{}}
\@writefile{toc}{\contentsline {section}{References}{5}{section*.2}\protected@file@percent }
\gdef \@abspage@last{5}
