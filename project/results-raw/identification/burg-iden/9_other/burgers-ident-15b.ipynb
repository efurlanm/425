{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "971c8858-057a-4bf3-affd-cdc210383e12",
   "metadata": {},
   "source": [
    "# Burgers - identification\n",
    "\n",
    "*2023-11-25*\n",
    "\n",
    "Based on: <https://github.com/maziarraissi/PINNs/tree/master/appendix/continuous_time_identification%20(Burgers)>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4875a621-dab9-444c-ac40-6ad56cd4595d",
   "metadata": {},
   "source": [
    "## Libraries & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22bb3af-cadc-4afe-9dc7-d0c39d08cfa4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%env TF_CPP_MIN_LOG_LEVEL=3\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "from scipy.interpolate import griddata\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import matplotlib.gridspec as gridspec\n",
    "import time\n",
    "import logging\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "my_rc_param = {'text.usetex': False}\n",
    "plt.rcParams.update(my_rc_param)\n",
    "\n",
    "import tensorflow as tf\n",
    "# logging.disable(logging.WARNING)\n",
    "# logging.getLogger('tensorflow').disabled = True\n",
    "# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "# tf.get_logger().setLevel(logging.ERROR)\n",
    "# tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "# Prevent tensorflow from allocating all GPU memory\n",
    "# configuration = tf.compat.v1.ConfigProto()\n",
    "# configuration.gpu_options.allow_growth = True\n",
    "# session = tf.compat.v1.Session(config=configuration)\n",
    "\n",
    "# For reproducibility\n",
    "np.random.seed(1234)\n",
    "tf.compat.v1.set_random_seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4de0b4d-f016-4ed8-b69e-59a316089f57",
   "metadata": {},
   "source": [
    "## Hyperparameters and other parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b6a0a5-1a02-4952-962d-f91314806770",
   "metadata": {},
   "outputs": [],
   "source": [
    "nu = 0.01/np.pi\n",
    "\n",
    "N_u = 2000\n",
    "\n",
    "layers = [2, 50, 50, 50, 50, 50, 50, 1]\n",
    "\n",
    "data = scipy.io.loadmat('burgers_shock.mat')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3539c6cc-dfd4-4305-b68e-60d5a2781557",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Plotting module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61595fe2-f0ad-4062-b778-354f61e3cccd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def figsize(scale, nplots=1):\n",
    "    fig_width_pt = 390.0  # Get this from LaTeX using \\the\\textwidth\n",
    "    inches_per_pt = 1.0 / 72.27  # Convert pt to inch\n",
    "\n",
    "    # Aesthetic ratio (you could change this)\n",
    "    golden_mean = (np.sqrt(5.0) - 1.0) / 2.0\n",
    "\n",
    "    fig_width = fig_width_pt * inches_per_pt * scale  # width in inches\n",
    "    fig_height = nplots * fig_width * golden_mean  # height in inches\n",
    "    fig_size = [fig_width, fig_height]\n",
    "    return fig_size\n",
    "\n",
    "def newfig(width, nplots=1):\n",
    "    # fig = plt.figure(figsize=figsize(width, nplots)) #latex\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2871f68a-bd3a-4d8e-afd0-fae0a1a74020",
   "metadata": {},
   "source": [
    "## PINN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b281d9b3-b372-4cf8-b299-2ef8b65c87bd",
   "metadata": {},
   "source": [
    "L-BFGS-B parameters\n",
    "<https://docs.scipy.org/doc/scipy/reference/optimize.minimize-lbfgsb.html>\n",
    "- *maxiter* - Maximum number of iterations.\n",
    "- *maxfun* - maximum number of function evaluations. Note that this function may violate the limit because of evaluating gradients by numerical differentiation.\n",
    "- *maxcor* - the maximum number of variable metric corrections used to define the limited memory matrix. (The limited memory BFGS method does not store the full hessian but uses this many terms in an approximation to it.)\n",
    "- *ftol* - the iteration stops when $(f^k - f^{k+1})/max{|f^k|,|f^{k+1}|,1}$ <= ftol.\n",
    "- *maxls* - maximum number of line search steps (per iteration). Default is 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e3cc3b-c2f8-417b-9d8a-ea6dbbfa952d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PhysicsInformedNN:\n",
    "\n",
    "    # Initialize the class\n",
    "    def __init__(self, X, u, layers, lb, ub):\n",
    "        self.lb = lb\n",
    "        self.ub = ub\n",
    "        self.x = X[:, 0:1]\n",
    "        self.t = X[:, 1:2]\n",
    "        self.u = u\n",
    "        self.layers = layers\n",
    "        # Initialize NNs\n",
    "        self.weights, self.biases = self.initialize_NN(layers)\n",
    "        # tf placeholders and graph\n",
    "        self.sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True,\n",
    "                                                     log_device_placement=True))\n",
    "        # Initialize parameters\n",
    "        self.lambda_1 = tf.Variable([0.0], dtype=tf.float32)\n",
    "        self.lambda_2 = tf.Variable([-6.0], dtype=tf.float32)\n",
    "        self.x_tf = tf.placeholder(tf.float32, shape=[None, self.x.shape[1]])\n",
    "        self.t_tf = tf.placeholder(tf.float32, shape=[None, self.t.shape[1]])\n",
    "        self.u_tf = tf.placeholder(tf.float32, shape=[None, self.u.shape[1]])\n",
    "        self.u_pred = self.net_u(self.x_tf, self.t_tf)\n",
    "        self.f_pred = self.net_f(self.x_tf, self.t_tf)\n",
    "        self.loss = ( tf.reduce_mean(tf.square(self.u_tf - self.u_pred)) +\n",
    "            tf.reduce_mean(tf.square(self.f_pred)) )\n",
    "        # https://docs.scipy.org/doc/scipy/reference/optimize.minimize-lbfgsb.html\n",
    "        self.optimizer = tf.contrib.opt.ScipyOptimizerInterface(\n",
    "            self.loss,\n",
    "            method='L-BFGS-B',\n",
    "            options={\n",
    "                'maxiter': 500000,\n",
    "                'maxfun': 50000,\n",
    "                'maxcor': 50,\n",
    "                'maxls': 50,\n",
    "                'ftol': 1.0 * np.finfo(float).eps\n",
    "            })\n",
    "        self.optimizer_Adam = tf.train.AdamOptimizer()\n",
    "        self.train_op_Adam = self.optimizer_Adam.minimize(self.loss)\n",
    "        init = tf.global_variables_initializer()\n",
    "        self.sess.run(init)\n",
    "\n",
    "    def initialize_NN(self, layers):\n",
    "        weights = []\n",
    "        biases = []\n",
    "        num_layers = len(layers)\n",
    "        for l in range(0, num_layers - 1):\n",
    "            W = self.xavier_init(size=[layers[l], layers[l + 1]])\n",
    "            b = tf.Variable(tf.zeros([1, layers[l + 1]], dtype=tf.float32),\n",
    "                            dtype=tf.float32)\n",
    "            weights.append(W)\n",
    "            biases.append(b)\n",
    "        return weights, biases\n",
    "\n",
    "    def xavier_init(self, size):\n",
    "        in_dim = size[0]\n",
    "        out_dim = size[1]\n",
    "        xavier_stddev = np.sqrt(2 / (in_dim + out_dim))\n",
    "        return tf.Variable(tf.truncated_normal([in_dim, out_dim],\n",
    "                                               stddev=xavier_stddev),\n",
    "                           dtype=tf.float32)\n",
    "\n",
    "    def neural_net(self, X, weights, biases):\n",
    "        num_layers = len(weights) + 1\n",
    "        H = 2.0 * (X - self.lb) / (self.ub - self.lb) - 1.0\n",
    "        for l in range(0, num_layers - 2):\n",
    "            W = weights[l]\n",
    "            b = biases[l]\n",
    "            H = tf.tanh(tf.add(tf.matmul(H, W), b))\n",
    "        W = weights[-1]\n",
    "        b = biases[-1]\n",
    "        Y = tf.add(tf.matmul(H, W), b)\n",
    "        return Y\n",
    "\n",
    "    def net_u(self, x, t):\n",
    "        u = self.neural_net(tf.concat([x, t], 1), self.weights, self.biases)\n",
    "        return u\n",
    "\n",
    "    def net_f(self, x, t):\n",
    "        lambda_1 = self.lambda_1\n",
    "        lambda_2 = tf.exp(self.lambda_2)\n",
    "        u = self.net_u(x, t)\n",
    "        u_t = tf.gradients(u, t)[0]\n",
    "        u_x = tf.gradients(u, x)[0]\n",
    "        u_xx = tf.gradients(u_x, x)[0]\n",
    "        f = u_t + lambda_1 * u * u_x - lambda_2 * u_xx\n",
    "        return f\n",
    "\n",
    "    def callback(self, loss, lambda_1, lambda_2):\n",
    "        print('Loss: %e, l1: %.5f, l2: %.5f' % (loss, lambda_1, np.exp(lambda_2)))\n",
    "\n",
    "    def train(self, nIter):\n",
    "        tf_dict = {self.x_tf: self.x, self.t_tf: self.t, self.u_tf: self.u}\n",
    "        start_time = time.time()\n",
    "        for it in range(nIter):\n",
    "            self.sess.run(self.train_op_Adam, tf_dict)\n",
    "            # Print\n",
    "            #if it % 10 == 0:\n",
    "            elapsed = time.time() - start_time\n",
    "            loss_value = self.sess.run(self.loss, tf_dict)\n",
    "            lambda_1_value = self.sess.run(self.lambda_1)\n",
    "            lambda_2_value = np.exp(self.sess.run(self.lambda_2))\n",
    "            print(\n",
    "                'It: %d, Loss: %.3e, Lambda_1: %.3f, Lambda_2: %.6f, Time: %.2f'\n",
    "                % (it, loss_value, lambda_1_value, lambda_2_value, elapsed))\n",
    "            start_time = time.time()\n",
    "\n",
    "        self.optimizer.minimize(\n",
    "            self.sess,\n",
    "            feed_dict=tf_dict,\n",
    "            fetches=[self.loss, self.lambda_1, self.lambda_2],\n",
    "            loss_callback=self.callback\n",
    "        )\n",
    "\n",
    "    def predict(self, X_star):\n",
    "        tf_dict = {self.x_tf: X_star[:, 0:1], self.t_tf: X_star[:, 1:2]}\n",
    "        u_star = self.sess.run(self.u_pred, tf_dict)\n",
    "        f_star = self.sess.run(self.f_pred, tf_dict)\n",
    "        return u_star, f_star"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172810e5-84bd-4ba7-8c09-910ede41313d",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604bc4b5-ebd4-4996-8351-2ec953627b08",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "t = data['t'].flatten()[:, None]\n",
    "x = data['x'].flatten()[:, None]\n",
    "Exact = np.real(data['usol']).T\n",
    "X, T = np.meshgrid(x, t)\n",
    "X_star = np.hstack((X.flatten()[:, None], T.flatten()[:, None]))\n",
    "u_star = Exact.flatten()[:, None]\n",
    "\n",
    "# Doman bounds\n",
    "lb = X_star.min(0)\n",
    "ub = X_star.max(0)\n",
    "\n",
    "idx = np.random.choice(X_star.shape[0], N_u, replace=False)\n",
    "X_u_train = X_star[idx, :]\n",
    "u_train = u_star[idx, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f42287-d211-4ad0-bfdb-2f08e1e1c708",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba37b614-af2d-469a-9985-9a355d1be207",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "model = PhysicsInformedNN(X_u_train, u_train, layers, lb, ub)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834a4cec-9c73-4700-8ac7-8e3ebe731d1a",
   "metadata": {},
   "source": [
    "## Train (the compute intensive part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21086f57-0ac3-4d4a-b8a8-a72f794abf07",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "model.train(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b307f0-1428-45a5-b672-18cc8f036225",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada07b5d-e09a-47ab-afca-7516eb5fe362",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "u_pred, f_pred = model.predict(X_star)\n",
    "U_pred = griddata(X_star, u_pred.flatten(), (X, T), method='cubic')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12bf880-a5a4-458b-aa77-4ad4f30c1762",
   "metadata": {},
   "source": [
    "## Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1b6b49-59b8-45a8-8c58-530fe44cfc6a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "error_u = np.linalg.norm(u_star - u_pred, 2) / np.linalg.norm(u_star, 2)\n",
    "lambda_1_value = model.sess.run(model.lambda_1)\n",
    "lambda_2_value = model.sess.run(model.lambda_2)\n",
    "lambda_2_value = np.exp(lambda_2_value)\n",
    "error_lambda_1 = np.abs(lambda_1_value - 1.0) * 100\n",
    "error_lambda_2 = np.abs(lambda_2_value - nu) / nu * 100\n",
    "print('Error u: %e' % (error_u))\n",
    "print('Error l1: %.5f%%' % (error_lambda_1))\n",
    "print('Error l2: %.5f%%' % (error_lambda_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01e900d-0832-4945-87fe-e8d32134caa6",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0a4722-7266-4cde-af94-a9faacc7382b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = newfig(1.0, 1.4)\n",
    "ax.axis('off')\n",
    "\n",
    "# u(t,x)\n",
    "\n",
    "gs0 = gridspec.GridSpec(1, 2)\n",
    "gs0.update(top=1 - 0.06,\n",
    "           bottom=1 - 1.0 / 3.0 + 0.06,\n",
    "           left=0.15,\n",
    "           right=0.85,\n",
    "           wspace=0)\n",
    "ax = plt.subplot(gs0[:, :])\n",
    "\n",
    "h = ax.imshow(U_pred.T,\n",
    "              interpolation='nearest',\n",
    "              cmap='rainbow',\n",
    "              extent=[t.min(), t.max(), x.min(),\n",
    "                      x.max()],\n",
    "              origin='lower',\n",
    "              aspect='auto')\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "fig.colorbar(h, cax=cax)\n",
    "\n",
    "ax.plot(X_u_train[:, 1],\n",
    "        X_u_train[:, 0],\n",
    "        'kx',\n",
    "        label='Data (%d points)' % (u_train.shape[0]),\n",
    "        markersize=2,\n",
    "        clip_on=False)\n",
    "\n",
    "line = np.linspace(x.min(), x.max(), 2)[:, None]\n",
    "ax.plot(t[25] * np.ones((2, 1)), line, 'w-', linewidth=1)\n",
    "ax.plot(t[50] * np.ones((2, 1)), line, 'w-', linewidth=1)\n",
    "ax.plot(t[75] * np.ones((2, 1)), line, 'w-', linewidth=1)\n",
    "\n",
    "ax.set_xlabel('$t$')\n",
    "ax.set_ylabel('$x$')\n",
    "ax.legend(loc='upper center',\n",
    "          bbox_to_anchor=(1.0, -0.125),\n",
    "          ncol=5,\n",
    "          frameon=False)\n",
    "ax.set_title('$u(t,x)$', fontsize=10)\n",
    "\n",
    "# u(t,x) slices\n",
    "\n",
    "gs1 = gridspec.GridSpec(1, 3)\n",
    "gs1.update(top=1 - 1.0 / 3.0 - 0.1,\n",
    "           bottom=1.0 - 2.0 / 3.0,\n",
    "           left=0.1,\n",
    "           right=0.9,\n",
    "           wspace=0.5)\n",
    "\n",
    "ax = plt.subplot(gs1[0, 0])\n",
    "ax.plot(x, Exact[25, :], 'b-', linewidth=2, label='Exact')\n",
    "ax.plot(x, U_pred[25, :], 'r--', linewidth=2, label='Prediction')\n",
    "ax.set_xlabel('$x$')\n",
    "ax.set_ylabel('u(t,x)')\n",
    "ax.set_title('$t = 0.25$', fontsize=10)\n",
    "ax.axis('square')\n",
    "ax.set_xlim([-1.1, 1.1])\n",
    "ax.set_ylim([-1.1, 1.1])\n",
    "\n",
    "ax = plt.subplot(gs1[0, 1])\n",
    "ax.plot(x, Exact[50, :], 'b-', linewidth=2, label='Exact')\n",
    "ax.plot(x, U_pred[50, :], 'r--', linewidth=2, label='Prediction')\n",
    "ax.set_xlabel('$x$')\n",
    "ax.set_ylabel('$u(t,x)$')\n",
    "ax.axis('square')\n",
    "ax.set_xlim([-1.1, 1.1])\n",
    "ax.set_ylim([-1.1, 1.1])\n",
    "ax.set_title('$t = 0.50$', fontsize=10)\n",
    "ax.legend(loc='upper center',\n",
    "          bbox_to_anchor=(0.5, -0.35),\n",
    "          ncol=5,\n",
    "          frameon=False)\n",
    "\n",
    "ax = plt.subplot(gs1[0, 2])\n",
    "ax.plot(x, Exact[75, :], 'b-', linewidth=2, label='Exact')\n",
    "ax.plot(x, U_pred[75, :], 'r--', linewidth=2, label='Prediction')\n",
    "ax.set_xlabel('$x$')\n",
    "ax.set_ylabel('$u(t,x)$')\n",
    "ax.axis('square')\n",
    "ax.set_xlim([-1.1, 1.1])\n",
    "ax.set_ylim([-1.1, 1.1])\n",
    "ax.set_title('$t = 0.75$', fontsize=10)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409cb941-c2b4-469b-966f-69b543bf55c4",
   "metadata": {},
   "source": [
    "### Identified PDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9f2767-b832-4e43-8ecf-0fc92968174f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(r'Correct PDE: u_t + u u_x - 0.0031831 u_{xx} = 0')\n",
    "print(r'Identified PDE (clean data): ',\n",
    "      r'u_t + %.5f u u_x - %.7f u_{xx} = 0' % (lambda_1_value, lambda_2_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f7751e-27a3-493b-ab68-95c5eb59776c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
